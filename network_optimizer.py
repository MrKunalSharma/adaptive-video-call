# -*- coding: utf-8 -*-
"""main_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xbcBdOfnj4x20rH1xGmCuwWshzEn1pUT
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import logging
import os
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import joblib

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NetworkOptimizer:
    def __init__(self, data_path):
        self.model = None
        self.scaler_X = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        self.features = ['bandwidth', 'throughput', 'packet_loss', 'latency', 'jitter']

        self.metric_bounds = {
            'bandwidth': {'min': 0.5, 'max': 6.0},
            'throughput': {'min': 0.9, 'max': 1.1},
            'packet_loss': {'min': 0.0, 'max': 1.0},
            'latency': {'min': 0.0, 'max': 41.0},
            'jitter': {'min': 0.0, 'max': 1000.0}
        }

        self.feature_weights = {
            'bandwidth': 1.5,
            'throughput': 2.0,
            'packet_loss': 1.0,
            'latency': 1.8,
            'jitter': 1.3
        }

        logger.info(f"Loading data from {data_path}")
        self.df = pd.read_csv(data_path)
        logger.info(f"Loaded dataset with {len(self.df)} samples")

        self.prepare_data()

    def validate_input(self, conditions):
        validated = {}
        for feature, value in conditions.items():
            bounds = self.metric_bounds[feature]
            validated[feature] = max(bounds['min'], min(bounds['max'], float(value)))
            if value != validated[feature]:
                logger.warning(f"{feature} value adjusted from {value} to {validated[feature]}")
        return validated

    def prepare_data(self):
        logger.info("Preparing dataset...")
        self.df_cleaned = self.df.copy()

        for col in self.features:
            self.df_cleaned[col] = pd.to_numeric(self.df_cleaned[col], errors='coerce')
            self.df_cleaned[col] = self.df_cleaned[col].fillna(self.df_cleaned[col].mean())

        self.df_cleaned['bandwidth_throughput_ratio'] = self.df_cleaned['bandwidth'] * self.df_cleaned['throughput']
        self.df_cleaned['jitter_latency_ratio'] = self.df_cleaned['jitter'] / (self.df_cleaned['latency'] + 1)

    def calculate_congestion(self, conditions):
        normalized_latency = conditions['latency'] / self.metric_bounds['latency']['max']
        normalized_jitter = conditions['jitter'] / self.metric_bounds['jitter']['max']
        normalized_bandwidth = conditions['bandwidth'] / self.metric_bounds['bandwidth']['max']
        throughput_deviation = abs(1 - conditions['throughput'])

        bandwidth_factor = 1 + (normalized_bandwidth * 0.5)

        base_congestion = (
            (normalized_latency * 35) +
            (normalized_jitter * 25) +
            (throughput_deviation * 25) +
            (normalized_bandwidth * 15)
        )

        congestion_score = base_congestion * bandwidth_factor

        if conditions['throughput'] < 0.95:
            congestion_score += 10

        if conditions['jitter'] > 100:
            congestion_score += 5

        return min(100, max(0, congestion_score))

    def train_model(self, model_save_path='network_optimizer_model.h5'):
        logger.info("Starting model training...")

        features = self.features + ['bandwidth_throughput_ratio', 'jitter_latency_ratio']
        X = self.df_cleaned[features]
        y = self.df_cleaned['bandwidth']

        X_scaled = self.scaler_X.fit_transform(X)
        y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1))

        scalers_dir = os.path.dirname(model_save_path)
        if not os.path.exists(scalers_dir) and scalers_dir:
            os.makedirs(scalers_dir)
        joblib.dump(self.scaler_X, os.path.join(scalers_dir, 'scaler_X.joblib'))
        joblib.dump(self.scaler_y, os.path.join(scalers_dir, 'scaler_y.joblib'))
        logger.info("Scalers saved successfully")


        X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

        self.model = Sequential([
            Dense(64, input_shape=(len(features),)),
            LeakyReLU(alpha=0.1),
            BatchNormalization(),
            Dropout(0.2),
            Dense(32),
            LeakyReLU(alpha=0.1),
            BatchNormalization(),
            Dropout(0.1),
            Dense(16),
            LeakyReLU(alpha=0.1),
            BatchNormalization(),
            Dense(1, activation='linear')
        ])

        self.model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )

        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=0.0001
            )
        ]

        history = self.model.fit(
            X_train, y_train,
            epochs=50,
            batch_size=8,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1
        )

        self.model.save(model_save_path)
        logger.info(f"Model saved at: {model_save_path}")

    def load_saved_model(self, model_path):
        try:
            self.model = load_model(model_path)
            logger.info(f"Model loaded from: {model_path}")
            scalers_dir = os.path.dirname(model_path)
            scaler_X_path = os.path.join(scalers_dir, 'scaler_X.joblib')
            scaler_y_path = os.path.join(scalers_dir, 'scaler_y.joblib')
            
            if os.path.exists(scaler_X_path) and os.path.exists(scaler_y_path):
                self.scaler_X = joblib.load(scaler_X_path)
                self.scaler_y = joblib.load(scaler_y_path)
                logger.info("Scalers loaded successfully")
            else:
                # If scalers don't exist, fit them on the training data
                logger.warning("Scalers not found. Fitting new scalers on the data.")
                features = self.features + ['bandwidth_throughput_ratio', 'jitter_latency_ratio']
                X = self.df_cleaned[features]
                y = self.df_cleaned['bandwidth']
                self.scaler_X.fit(X)
                self.scaler_y.fit(y.values.reshape(-1, 1))
                
                # Save the newly fitted scalers
                joblib.dump(self.scaler_X, scaler_X_path)
                joblib.dump(self.scaler_y, scaler_y_path)
            return True
        except Exception as e:
            logger.error(f"Error loading model: {str(e)}")
            return False

    def predict_single(self, conditions):
        validated_conditions = self.validate_input(conditions)
        optimal_bw, quality_score, initial_congestion, final_congestion = self.get_optimal_bandwidth(validated_conditions)

        return {
            "optimal_bandwidth": float(optimal_bw),
            "quality_score": float(quality_score),
            "initial_congestion": float(initial_congestion),
            "final_congestion": float(final_congestion)
        }

    def get_optimal_bandwidth(self, conditions):
            initial_congestion = self.calculate_congestion(conditions)
            original_bandwidth = conditions['bandwidth']

            # Store original conditions for comparison
            original_conditions = conditions.copy()
            
            # Calculate features for prediction
            conditions['bandwidth_throughput_ratio'] = conditions['bandwidth'] * conditions['throughput']
            conditions['jitter_latency_ratio'] = conditions['jitter'] / (conditions['latency'] + 1)

            features = self.features + ['bandwidth_throughput_ratio', 'jitter_latency_ratio']
            input_data = pd.DataFrame([conditions])[features]
            input_scaled = self.scaler_X.transform(input_data)

            predicted_bandwidth = self.model.predict(input_scaled)[0][0]
            optimal_bandwidth = self.scaler_y.inverse_transform([[predicted_bandwidth]])[0][0]

            optimal_bandwidth = max(self.metric_bounds['bandwidth']['min'],
                                min(self.metric_bounds['bandwidth']['max'], optimal_bandwidth))
            
            # Ensure the bandwidth difference is at least 0.05 Mbps
            bandwidth_diff = abs(optimal_bandwidth - original_bandwidth)
            if bandwidth_diff < 0.05:
                # If change is too small, use something more noticeable (Â±5% of current)
                if optimal_bandwidth > original_bandwidth:
                    optimal_bandwidth = min(original_bandwidth * 1.05, self.metric_bounds['bandwidth']['max'])
                else:
                    optimal_bandwidth = max(original_bandwidth * 0.95, self.metric_bounds['bandwidth']['min'])
            
            # Update conditions with new bandwidth
            test_conditions = original_conditions.copy()
            test_conditions['bandwidth'] = optimal_bandwidth
            test_conditions['bandwidth_throughput_ratio'] = test_conditions['bandwidth'] * test_conditions['throughput']
            
            # Calculate new congestion with optimal bandwidth
            final_congestion = self.calculate_congestion(test_conditions)
            
            # Calculate congestion reduction (ensure it's positive)
            congestion_reduction = max(0, initial_congestion - final_congestion)
            
            # If zero reduction, make a small positive value for better UX
            if congestion_reduction == 0 and optimal_bandwidth != original_bandwidth:
                congestion_reduction = 0.5  # Small positive value
            
            quality_score = self.calculate_quality_score(test_conditions, optimal_bandwidth)

            return optimal_bandwidth, quality_score, initial_congestion, final_congestion

    def calculate_quality_score(self, conditions, bandwidth):
        score = 100
        throughput_deviation = abs(1 - conditions['throughput'])
        score -= throughput_deviation * 20
        score -= (conditions['latency'] / self.metric_bounds['latency']['max']) * 15
        score -= (conditions['jitter'] / self.metric_bounds['jitter']['max']) * 15
        return max(0, min(100, score))

